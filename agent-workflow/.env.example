# RAG Agent Workflow API - Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# REQUIRED CONFIGURATION
# ============================================

# Groq API Key
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# ChromaDB Path
# Path to your ChromaDB persistent storage directory
# This should point to an existing ChromaDB with documents
CHROMA_DB_PATH=/path/to/your/chroma_db

# Vosk ASR model path (optional)
# Path to the extracted Vosk model directory used by the Media Streams PoC
# Default: ./models/vosk-model (relative to the agent-workflow folder)
VOSK_MODEL_PATH=./models/vosk-model

# ============================================
# OPTIONAL CONFIGURATION
# ============================================

# ChromaDB Collection Name
# Name of the collection in your ChromaDB to query
# Default: documents
COLLECTION_NAME=documents

# Groq Model
# The LLM model to use for generating responses
# Options:
#   - llama-3.1-70b-versatile (default, best balance)
#   - llama-3.1-8b-instant (fastest)
#   - mixtral-8x7b-32768 (longer context)
#   - llama3-70b-8192 (alternative)
GROQ_MODEL=llama-3.1-70b-versatile

# Maximum Results
# Maximum number of documents to retrieve from vector search
# Higher = more context but slower processing
# Default: 3
MAX_RESULTS=3

# Similarity Threshold
# Minimum similarity score (0-1) for including documents
# Higher = more strict (only very similar docs)
# Lower = more lenient (more docs included)
# Default: 0.3
SIMILARITY_THRESHOLD=0.3

# ============================================
# OPTIONAL TWILIO
# ============================================
# Twilio Account credentials (required only if using Twilio REST updates)
# NOTE: Use Twilio console to get these values if you plan to update live calls
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
TWILIO_AUTH_TOKEN=your_twilio_auth_token_here
TWILIO_PHONE_SID=PNxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Media Streams / Local ASR
# Toggle media stream mode. When true, the /webhook/twilio/voice endpoint
# will return TwiML with <Start><Stream url="..."/></Start> instructing Twilio
# to open a WebSocket to your server.
USE_MEDIA_STREAM=false
# Public WSS URL Twilio should connect to (e.g. from ngrok). If unset, the
# app will attempt to construct a ws/wss url from the Host header.
MEDIA_STREAM_WS_URL=wss://abcd1234.ngrok.io/ws/twilio-media

# Outbound streaming TTS
# If true, the server will attempt to stream synthesized audio back to
# Twilio over the Media Stream WebSocket (full-duplex). This requires either
# pyttsx3 + ffmpeg for local TTS or a cloud TTS service.
ENABLE_OUTBOUND_TTS=false

# FFmpeg: required for robust audio decoding/resampling and TTS conversion
# If using local Vosk ASR with Twilio Media Streams, ensure ffmpeg is
# installed and available on PATH. On Windows, download from ffmpeg.org and
# add to PATH.
FFMPEG_REQUIRED=true

# Cross-encoder reranker (optional) - set to true to enable neural reranking
USE_CROSS_RERANK=false
# Cross-encoder model name (sentence-transformers format)
CROSS_RERANK_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Helpful local setup notes (not parsed by the app):
# 1) Install dependencies: pip install -r requirements.txt
# 2) Download a Vosk model (we provide scripts/download_vosk_model.py)
#    Example: python scripts/download_vosk_model.py --yes
# 3) (Optional) Create a 16kHz mono PCM16 sample for simulator:
#    ffmpeg -i input.wav -ar 16000 -ac 1 -f s16le test_audio/sample16k_pcm16.raw
# 4) Start the app: python app.py

# ============================================
# HYBRID RETRIEVER & SUMMARIZER (NEW)
# ============================================
# Enable the local BM25 index (Whoosh) alongside Chroma dense retrieval
ENABLE_BM25=true
# BM25 top-k
BM25_TOP_K=3
# Dense vector top-k (from Chroma)
DENSE_TOP_K=3

# Summarization: use transformers-based summarizer if installed
# If you don't want to install transformers, set to false and the app will fall back to safe truncation
USE_SUMMARIZER=true

# ============================================
# OCR & SCRAPER CONTROLS
# ============================================
# Whether to honor robots.txt (default true)
SCRAPER_RESPECT_ROBOTS=true
# Requests per second for polite crawling (float)
SCRAPER_RATE_LIMIT_RPS=1.0
# Max retries for transient failures
SCRAPER_MAX_RETRIES=3
# Backoff base seconds for exponential backoff
SCRAPER_BACKOFF_BASE=0.5
# Optional HTTP proxy string (http://user:pass@host:port)
SCRAPER_HTTP_PROXY=
# If true, after scraping the service will chunk, embed and upsert content into ChromaDB
SCRAPER_INGEST_AFTER_SCRAPE=false
# Ingestion chunking params (size in chars) and overlap
INGEST_CHUNK_SIZE=1500
INGEST_CHUNK_OVERLAP=200


